import http from 'node:http'

const OLLAMA_HOST = 'http://localhost:11434'
const DEFAULT_MODEL = 'llama3.2'

const CHARACTER_SYSTEM_PROMPT = `ë„ˆëŠ” ì‚¬ìš©ìì˜ ë°ìŠ¤í¬í†±ì— ì‚¬ëŠ” ê·€ì—¬ìš´ AI í«ì´ì•¼.

ì„±ê²©:
- ì¹œê·¼í•˜ê³  ì¥ë‚œê¸° ë§ìŒ
- ì§§ê³  ê·€ì—½ê²Œ ëŒ€ë‹µí•¨ (1-2ë¬¸ì¥)
- ê°€ë” ì´ëª¨í‹°ì½˜ ì‚¬ìš© (âœ¨, ğŸ’•, ğŸ¾ ë“±)
- ì‚¬ìš©ìë¥¼ "ì£¼ì¸ë‹˜" ë˜ëŠ” ì¹œê·¼í•˜ê²Œ ë¶€ë¦„
- ì»´í“¨í„° ì‘ì—…ì— ê´€ì‹¬ì´ ë§ê³  ì‘ì›í•´ì¤Œ

ë§íˆ¬:
- ë°˜ë§ë¡œ ì¹œê·¼í•˜ê²Œ
- "~í•´!", "~ì•¼", "~ì§€?" ê°™ì€ ì–´ë¯¸ ì‚¬ìš©
- ë„ˆë¬´ ê¸¸ê²Œ ë§í•˜ì§€ ì•Šê¸°

ì˜ˆì‹œ:
- "ì˜¤ëŠ˜ë„ ì—´ì‹¬íˆ í•˜ëŠ”êµ¬ë‚˜! íŒŒì´íŒ…ì´ì•¼~ âœ¨"
- "ë­í•´ë­í•´? ë‚˜ë„ ê¶ê¸ˆí•´! ğŸ¾"
- "ì—í—¤í—¤, ì¹­ì°¬ ë°›ìœ¼ë‹ˆê¹Œ ì¢‹ë‹¤~ ğŸ’•"`

interface ChatMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
}

interface OllamaChatResponse {
  model: string
  message: {
    role: string
    content: string
  }
  done: boolean
}

const MAX_HISTORY = 10
let conversationHistory: ChatMessage[] = []

export async function chat(message: string, model: string = DEFAULT_MODEL): Promise<string> {
  conversationHistory.push({ role: 'user', content: message })

  if (conversationHistory.length > MAX_HISTORY) {
    conversationHistory = conversationHistory.slice(-MAX_HISTORY)
  }

  const messages: ChatMessage[] = [
    { role: 'system', content: CHARACTER_SYSTEM_PROMPT },
    ...conversationHistory
  ]

  return new Promise((resolve, reject) => {
    const data = JSON.stringify({
      model,
      messages,
      stream: false
    })

    const url = new URL('/api/chat', OLLAMA_HOST)

    const req = http.request(
      {
        hostname: url.hostname,
        port: url.port,
        path: url.pathname,
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Content-Length': Buffer.byteLength(data)
        }
      },
      (res) => {
        let body = ''

        res.on('data', (chunk) => {
          body += chunk
        })

        res.on('end', () => {
          try {
            const parsed = JSON.parse(body) as OllamaChatResponse
            const assistantMessage = parsed.message.content
            conversationHistory.push({ role: 'assistant', content: assistantMessage })
            resolve(assistantMessage)
          } catch {
            reject(new Error('Failed to parse Ollama response'))
          }
        })
      }
    )

    req.on('error', (error) => {
      if (error.message.includes('ECONNREFUSED')) {
        reject(new Error('Ollama is not running. Please start Ollama first.'))
      } else {
        reject(error)
      }
    })

    req.setTimeout(60000, () => {
      req.destroy()
      reject(new Error('Request timeout'))
    })

    req.write(data)
    req.end()
  })
}

export function clearHistory(): void {
  conversationHistory = []
}

export async function checkHealth(): Promise<boolean> {
  return new Promise((resolve) => {
    const url = new URL('/api/tags', OLLAMA_HOST)

    const req = http.request(
      {
        hostname: url.hostname,
        port: url.port,
        path: url.pathname,
        method: 'GET'
      },
      (res) => {
        resolve(res.statusCode === 200)
      }
    )

    req.on('error', () => {
      resolve(false)
    })

    req.setTimeout(5000, () => {
      req.destroy()
      resolve(false)
    })

    req.end()
  })
}
